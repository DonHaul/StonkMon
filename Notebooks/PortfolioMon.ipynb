{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import math\n",
    "import altair as alt\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import multiprocessing  \n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "import defs\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "import re\n",
    "\n",
    "import requests_cache\n",
    "#requests_cache.install_cache(cache_name=\"cache_cache\", backend='sqlite')\n",
    "requests_cache.uninstall_cache()\n",
    "\n",
    "def Logging(val):\n",
    "    with open(\"log.txt\") as file: # Use file to refer to the file object\n",
    "        file.write(val)\n",
    "\n",
    "\n",
    "#missing777\n",
    "#fees\n",
    "#dividends\n",
    "#stocksplits - what happens in  a stock split(are old shares amount converted to new share amount)\n",
    "#confirm values, see if value is between open and close of that day\n",
    "#drop columns when amount is 0\n",
    "\n",
    "def return_print(msg=\"\",payload=None,status=\"INFO\"):\n",
    "    \n",
    "    payload={}\n",
    "    if payload is None:\n",
    "        payload=payload\n",
    "\n",
    "    payload['status']=status\n",
    "    payload['msg']=msg\n",
    "    \n",
    "    print(json.dumps(payload))\n",
    "\n",
    "from random_proxies import random_proxy\n",
    "\n",
    "\n",
    "#TODO\n",
    "#fees \n",
    "#dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asyncio\n",
      "  Downloading https://files.pythonhosted.org/packages/22/74/07679c5b9f98a7cb0fc147b1ef1cc1853bc07a4eb9cb5731e24732c5f773/asyncio-3.4.3-py3-none-any.whl (101kB)\n",
      "Installing collected packages: asyncio\n",
      "Successfully installed asyncio-3.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Transactions\n",
      "Transactions Loaded\n"
     ]
    }
   ],
   "source": [
    "#cross results from summaries with results from download\n",
    "filename = 'Finance_Positions.csv'\n",
    "\n",
    "f = open(filename, \"r\")\n",
    "\n",
    "count_comma=0\n",
    "count_semicolon=0\n",
    "for i in range(2):\n",
    "    line = f.readline()\n",
    "    count_comma=count_comma+line.count(\",\")\n",
    "    count_semicolon=count_semicolon+line.count(\";\")\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(\"Importing Transactions\")\n",
    "\n",
    "sep=\",\"\n",
    "if(count_semicolon>count_comma):\n",
    "    sep=\";\"\n",
    "\n",
    "#transactions list\n",
    "transactions = pd.read_csv(filename,sep=sep)\n",
    "\n",
    "#get the most earliest date\n",
    "df=pd.DataFrame()\n",
    "df['Date']=transactions['When']\n",
    "\n",
    "#the start date\n",
    "startdate=pd.to_datetime(df['Date']).sort_values()[0].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#get all use tickers distinct\n",
    "stonks=pd.unique(transactions['Ticker']).tolist()\n",
    "\n",
    "print(\"Transactions Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "None\n",
      "SEED\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check if in db\n",
    "\n",
    "con = sqlite3.connect(\"example.db\")\n",
    "cursy = con.cursor()\n",
    "    \n",
    "stonk_summaries={}\n",
    "stonk_summaries_missing =[]\n",
    "\n",
    "#consider paraleliszing\n",
    "for s in stonks:\n",
    "    \n",
    "    print(s)\n",
    "    \n",
    "    cursy.execute('SELECT * FROM stocks_summary where ticker==?',(s,))\n",
    "    #df = pd.read_sql_query(\"SELECT * from stocks_summary where ticker = ?\".formar(, con)\n",
    "\n",
    "    rows = cursy.fetchone()\n",
    "    if rows is not None:\n",
    "        stonk_summaries[rows[0]]=json.loads(rows[1])\n",
    "    else:\n",
    "        stonk_summaries_missing.append(s)\n",
    "    \n",
    "    print(rows)\n",
    "cursy.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', 'SEED']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stonk_summaries\n",
    "stonk_summaries_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2']\n"
     ]
    }
   ],
   "source": [
    "#get from requests\n",
    "import requests\n",
    "\n",
    "lst = ['AAPL']\n",
    "response = requests.post('http://localhost:3000/api/stoccies', json={'stonks':stonk_summaries_missing})\n",
    "response.content\n",
    "\n",
    "#print errors:\n",
    "print(\"ERRORES ARE:\",json.loads(response.content)['ERRORS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "summaries={}\n",
    "with open('merger.json') as f:\n",
    "  summaries = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(summaries['XOM']['summaryDetail']['currency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(tickers=['TSLA'],start='2020-08-05',end='2020-09-05',interval='1d',group_by='column',prepos=False,threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SaveSummaryToDB(summaries):\n",
    "    con = sqlite3.connect(\"example.db\")\n",
    "    cursy = con.cursor()\n",
    "\n",
    "    for key in summaries:\n",
    "        print(key)\n",
    "\n",
    "        try:               \n",
    "\n",
    "            #cursy.execute('INSERT INTO stocks_summary(ticker,summary) VALUES (?,?)', ( key, json.dumps(summaries[key])))\n",
    "            cursy.execute('INSERT INTO stocks_currency(ticker,currency) VALUES (?,?)', ( key,summaries[key]['summaryDetail']['currency']))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            cursy.execute('INSERT INTO error_log VALUES (?,?)', ( str(e),))\n",
    "\n",
    "            print(\"Whoopsie\")\n",
    "\n",
    "    con.commit()\n",
    "    cursy.close()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#call  summary api \n",
    "\n",
    "#check db, if not, call api\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "response = requests.post('http://localhost:3000/api/stoccies', data={'stonks':['TSLA']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "#load missing\n",
    "con = sqlite3.connect(\"example.db\")\n",
    "df = pd.read_sql_query(\"SELECT * from stocks_currency\", con)\n",
    "\n",
    "c = set(stonks).difference(set(df.ticker))\n",
    "df = pd.read_sql_query(\"SELECT * from stocks_error\", con)\n",
    "#c = set(c).difference(set(df.ticker))\n",
    "stonks_missing=list(c)\n",
    "len(stonks_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def log_result(result):\n",
    "    # This is called whenever foo_pool(i) returns a result.\n",
    "    # result_list is modified only by the main process, not the pool workers.\n",
    "\n",
    "    try:\n",
    "        #inf=defs.FetchTickerInfo(i)\n",
    "\n",
    "        print(\"Fetched\")\n",
    "\n",
    "        cony = sqlite3.connect('example.db')\n",
    "        cursy = cony.cursor()\n",
    "        print(\"Inserting\")\n",
    "        print(result[0])\n",
    "\n",
    "        x = re.findall(\"\\\"currency\\\":\\\"(.*?)\\\"\", result[1].decode('UTF-8'))#.decode('UTF-8')\n",
    "        \n",
    "        if len(x)>0:\n",
    "            cursy.execute('INSERT INTO stocks_currency VALUES (?,?)', ( result[0], x[0]))\n",
    "            cony.commit()\n",
    "            print(result[0],x)\n",
    "        else:\n",
    "            cursy.execute('INSERT INTO stocks_error VALUES (?)', (result[0],))\n",
    "            cony.commit()\n",
    "            print(result[0],\"err\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Whoopsie\")\n",
    "\n",
    "\n",
    "\n",
    "#multithread load of stocks not already obtained \n",
    "infos=[]\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(32)\n",
    "    #infos = pool.map(defs.FetchTickerInfo, stonks_missing)\n",
    "\n",
    "    count=0\n",
    "    for i in stonks_missing:\n",
    "        count=count+1\n",
    "        print(count)\n",
    "        pool.apply_async(defs.FetchTickerInfo3, args = (i, ), callback = log_result)\n",
    "    print(\"Thread Started\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    #print(result_list)\n",
    "\n",
    "#get current format\n",
    "curtime=datetime.datetime.now().isoformat()\n",
    "\n",
    "stonks_to_add = []\n",
    "\n",
    "for tick, inf in zip(stonks_missing,infos):\n",
    "\n",
    "\n",
    "    stonks_info[tick] = inf\n",
    "    stonks_to_add.append((tick, json.dumps(inf),curtime))\n",
    "\n",
    "#save to avoid future big times\n",
    "cur.executemany('INSERT INTO stocks_info VALUES (?,?,?)', stonks_to_add)\n",
    "\n",
    "\n",
    "#T16 - 13\n",
    "#T4 - 26 \n",
    "print(time.time()-start)\n",
    "\n",
    "con.commit()\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defs.FetchTickerInfo3(\"TPOP.L\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = re.findall(\"\\\"currency\\\":\\\"(.*?)\\\"\", res[1].decode('UTF-8'))#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#donwload all data\n",
    "data = yf.download(tickers=stonks,start=startdate,interval='1d',group_by='column',prepos=False,threads=True)\n",
    "\n",
    "pairs = yf.download(tickers=\"EURUSD=X\",start=startdate,interval='1d',group_by='column',prepos=False,threads=True)\n",
    "\n",
    "#counts entries without values\n",
    "empty_stocks  =data['Close'].columns[data['Close'].count()==0].to_list()\n",
    "\n",
    "if len(empty_stocks)>0:\n",
    "    payload= {}\n",
    "    payload['stocks'] = empty_stocks\n",
    "    return_print(\"The Following Tickers are Invalid:\"+\" \".join(empty_stocks)+\"\\n, tickers must be set accordingly to  https://finance.yahoo.com/\",payload,status='ERROR')\n",
    "\n",
    "return_print(\"Stock Values Loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stonkdict={}\n",
    "\n",
    "\n",
    "targetcurrency='EUR'\n",
    "\n",
    "superdf =pd.DataFrame()\n",
    "print(superdf.empty)\n",
    "\n",
    "i=0\n",
    "\n",
    "\n",
    "for stonk in stonks:  \n",
    "    \n",
    "    print(stonk)\n",
    "    \n",
    "    #get transactions from csv\n",
    "    singlestock_transactions = transactions[transactions['Ticker']==stonk]\n",
    "\n",
    "    #use index to create df\n",
    "    index = data.index\n",
    "    df=pd.DataFrame(index=data.index)\n",
    "\n",
    "    \n",
    "    #extract price\n",
    "    df['Price']= data['Close'][stonk]\n",
    "    #initialize amount\n",
    "    df[\"SharesOwned\"]=0\n",
    "    #initialize total value\n",
    "    df['TotalValue']=0   \n",
    "\n",
    "    df['InvestedValue']=0   \n",
    "\n",
    "    #set ticker\n",
    "    df[\"Ticker\"]=stonk\n",
    "    \n",
    "    #fetch currency\n",
    "    df[\"Currency\"]=json.loads(stonks_info['DIOD'][1])['currency']\n",
    "\n",
    "\n",
    "    for idx, row in singlestock_transactions.iterrows():\n",
    "\n",
    "        multiplier = 1\n",
    "        if(row['What']=='buy'):\n",
    "            multiplier=1\n",
    "        elif(row['What']=='sell'):\n",
    "            multiplier=-1\n",
    "        else:\n",
    "            raise Exception(\"Transaction \\\"row['What']\\\" is not recognized\")\n",
    "\n",
    "        #print(row['Amount'])\n",
    "\n",
    "\n",
    "        #CHECK IF IT GETS APPLIED TO STARTING ARRAY, FIND AWAY TO DO THIS AT THE START\n",
    "        #CONVERTING INTO AMOUNT MAKES it be adimensional, and doenst matter what currency it was bought in\n",
    "        try:\n",
    "            if(math.isnan(float(row['Amount']))):\n",
    "                row['Amount']=row['Total Cost']/row['Cost per Share']\n",
    "        except:\n",
    "            row['Amount']=row['Total Cost']/row['Cost per Share']\n",
    "\n",
    "\n",
    "        #df[row['When']:][stonk+\" Amount\"] = df[row['When']:][stonk+\" Amount\"]=row['Amount']\n",
    "\n",
    "        #df[row['When']:,stonk+\" Amount\"] = df[row['When']:,stonk+\" Amount\"]+row['Amount']\n",
    "\n",
    "        #print(float(row['Amount']))\n",
    "        \n",
    "        if pd.to_datetime(\"now\")<pd.to_datetime(row['When']):\n",
    "            print(row['When'],\"<- This date is in the future, and will not be considere\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        \n",
    "        #print(float(row['Amount'])*multiplier)\n",
    "        #set amount to the amount\n",
    "        #display(row['When'])\n",
    "        #display(df.loc[row['When']:])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #change the amount from whtn to forward,  multiplier determinex if its a  buy of a sell\n",
    "        df.loc[row['When']:,'SharesOwned'] = df.loc[row['When']:,'SharesOwned'] + (float(row['Amount'])*multiplier)\n",
    "\n",
    "        #money put in\n",
    "        df.loc[row['When']:,'InvestedValue'] = df.loc[row['When']:,'InvestedValue'] + (float(row['Total Cost'])*multiplier)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    i=i+1\n",
    "        \n",
    "    df.loc[:,'TotalValue']= df[\"Price\"]*df['SharesOwned']\n",
    "    df.loc[:,'EarnedValue']= df.loc[:,'TotalValue']-df.loc[:,'InvestedValue']\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #delete rows with no data\n",
    "    #\n",
    "    df.interpolate(inplace=True)\n",
    "    df.dropna(inplace=True,how='any')\n",
    "    \n",
    "    \n",
    "    #display(df)\n",
    "    #display(df)\n",
    "    \n",
    "    superdf= superdf.append(df)\n",
    "    #display(df)\n",
    "    #display(superdf)\n",
    "    #print(\"YIKES\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superdf['CurrencyUSD']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fauxpair = pairs.loc[:]['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hm = pd.merge(\n",
    "    superdf,\n",
    "    fauxpair,\n",
    "    how=\"left\",\n",
    "    left_on='Date',\n",
    "    right_on='Date',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "\n",
    "hm.loc[:]['Close']=hm.loc[:]['Close'].interpolate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect('example.db')\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "# Create table\n",
    "cur.execute('''CREATE TABLE stocks_info (ticker text, info text,dateinserted TEXT )''')\n",
    "\n",
    "               # Save (commit) the changes\n",
    "#cur.execute('DROP TABLE stocks_info')\n",
    "#cur.execute('DROP TABLE stocks')\n",
    "\n",
    "con.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB('db.json')\n",
    "db.insert({'type': 'apple', 'count': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tinydb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df.loc[row['When']:,'Amount'] = df.loc[row['When']:,'Amount'] + (float(row['Amount'])*multiplier)\n",
    "hm.loc[:,hm['Currency']=='EUR'] = hm.loc[:,'Close']*hm.loc[:,'TotalValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecct column based on another column\n",
    "hm.loc[hm['Currency']=='EUR',['Currency']]\n",
    "\n",
    "\n",
    "#hm.loc[:,hm['Currency']=='EUR']['Close']\n",
    "#hm[hm['Currency']=='EUR']['Currency']\n",
    "#rectify us currency\n",
    "\n",
    "#convert currency\n",
    "hm.loc[:,'TotalValueUSD']=0\n",
    "hm.loc[:,'TotalValueUSD']=hm.loc[:,'TotalValue']\n",
    "hm.loc[hm['Currency']=='EUR','TotalValueUSD'] = hm[hm['Currency']=='EUR']['TotalValue']*hm[hm['Currency']=='EUR']['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time()-startu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#superdf[superdf['Ticker']=='XOM']\n",
    "dfforaltair = superdf.loc[\"2019-10-20\":].reset_index()\n",
    "dfforaltair.interpolate(inplace=True)\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "alt.Chart(dfforaltair).mark_area().encode(\n",
    "    x='Date',\n",
    "    y='TotalValue',\n",
    "    #color='Ticker:N',\n",
    "    color=alt.Color('Ticker:N', legend=alt.Legend(columns=1,symbolLimit=300)),\n",
    ").properties(\n",
    "    width=1280,\n",
    "    height=720\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in stonkdict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "702*0.50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.loc['04/02/2020':, 'TSLAR'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['1962-01-02':]][stonk+\" Amount\"]=df[df['1962-01-02':]][stonk+\" Amount\"]+row['Amount']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install stocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitd7e8ed98d0fa46a1bc894a209907a008"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
